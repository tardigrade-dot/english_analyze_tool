import streamlit as st
import json
import pandas as pd
import re
import time
import hashlib
import html  # æ–°å¢ï¼šç”¨äº HTML è½¬ä¹‰
from openai import OpenAI

# --- ç¼“å­˜é…ç½® ---
CACHE_SIZE_LIMIT = 10
CACHE_TTL_SECONDS = 30

# åˆå§‹åŒ–ç¼“å­˜
if 'llm_cache' not in st.session_state:
    st.session_state.llm_cache = {}

modelscope_key = st.secrets["modelscope"]["key"]
# å®¢æˆ·ç«¯é…ç½®ï¼ˆè¯·æŒ‰éœ€é…ç½®ï¼‰
modelscope_client = OpenAI(
    base_url='https://api-inference.modelscope.cn/v1',
    api_key=modelscope_key
)

# æ¨¡å‹é…ç½®
model_type = "modelscope"  # æˆ– "ollama"
# model_name = "gemma3n:latest"  # ollama
model_name = 'Qwen/Qwen3-235B-A22B-Instruct-2507'  # modelscope

# --- æ¨¡æ‹Ÿå‡½æ•°ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰---
def get_mock_json_response(prompt_content):
    sentence_match = re.search(r'### \*\*å¾…åˆ†æçš„è‹±æ–‡é•¿å¥\*\*\n(.*?)\n', prompt_content, re.DOTALL)
    sentence = sentence_match.group(1).strip() if sentence_match else ""

    if not sentence:
        return json.dumps({"error": "No sentence provided"})

    res_json_dict = {
        "Source Sentence": sentence,
        "Translation": "å°½ç®¡è¯¥å®£è¨€æ‰¿è¯ºæ­¤åæœªç»æ°‘é€‰ç«‹æ³•æœºæ„æ‰¹å‡†çš„æ³•å¾‹ä¸ä¼šç”Ÿæ•ˆï¼Œä½†æ³•é™¢ä¼¼ä¹æ²¡æœ‰æ„è¯†åˆ°è¿™ä¸€æ‰¿è¯ºåŒ…å«äº†ä¸€ä»½å®ªæ³•æ€§æ–‡ä»¶ã€‚",
        "StructureAnalysis": [
            {
                "segment": "Although the manifesto pledged that henceforth no law would go into effect without the approval of a popularly elected legislature",
                "highlight": True,
                "role": "è®©æ­¥çŠ¶è¯­ä»å¥ (Adverbial Clause of Concession)",
                "explanation_cn": "ç”±è¿è¯â€œAlthoughâ€å¼•å¯¼ï¼Œè¯´æ˜äº†ä¸»å¥åŠ¨ä½œå‘ç”Ÿçš„èƒŒæ™¯æˆ–æ¡ä»¶ã€‚"
            },
            {
                "segment": ", ",
                "highlight": False,
                "role": "",
                "explanation_cn": ""
            },
            {
                "segment": "the Court seemed unaware",
                "highlight": True,
                "role": "ä¸»å¥æ ¸å¿ƒ (Main Clause Core)",
                "explanation_cn": "ä¸»è¯­å’Œä¸»è¦è°“è¯­åŠ¨è¯ï¼Œè¡¨è¾¾äº†æ³•é™¢ä¼¼ä¹æ²¡æœ‰æ„è¯†åˆ°æŸä¸ªäº‹å®ã€‚"
            },
            {
                "segment": " that this pledge entailed a constitutional charter.",
                "highlight": True,
                "role": "å®¾è¯­è¡¥è¶³è¯­ä»å¥ (Complement to 'unaware')",
                "explanation_cn": "ç”±'that'å¼•å¯¼ï¼Œå…·ä½“è¯´æ˜äº†æ³•é™¢æ²¡æœ‰æ„è¯†åˆ°çš„å†…å®¹ã€‚"
            }
        ],
        "Vocabulary": [
            {
                "word": "manifesto",
                "pos": "n.",
                "definition": "å®£è¨€ï¼Œå£°æ˜",
                "example": "The party issued a manifesto outlining its goals. (è¯¥å…šå‘å¸ƒäº†ä¸€ä»½é˜è¿°å…¶ç›®æ ‡çš„å®£è¨€ã€‚)"
            },
            {
                "word": "henceforth",
                "pos": "adv.",
                "definition": "ä»ä»Šä»¥åï¼Œæ­¤å",
                "example": "Henceforth, all meetings will be held online. (ä»ä»Šä»¥åï¼Œæ‰€æœ‰ä¼šè®®éƒ½å°†åœ¨ç½‘ä¸Šä¸¾è¡Œã€‚)"
            },
            {
                "word": "entailed",
                "pos": "v. (è¿‡å»å¼)",
                "definition": "ä½¿â€¦â€¦æˆä¸ºå¿…éœ€ï¼›ç‰µæ¶‰ï¼ŒåŒ…å«",
                "example": "The job entailed a lot of travelling. (è¿™ä»½å·¥ä½œéœ€è¦ç»å¸¸å‡ºå·®ã€‚)"
            }
        ],
        "Decomposition": [
            {
                "id": 1,
                "function": "è®©æ­¥æ¡ä»¶",
                "simplified_sentence_en": "The manifesto contained a promise about future laws."
            },
            {
                "id": 2,
                "function": "æ ¸å¿ƒä¸»å¹²",
                "simplified_sentence_en": "The Court appeared to be unaware of a critical fact."
            },
            {
                "id": 3,
                "function": "æœªæ„è¯†åˆ°çš„å†…å®¹",
                "simplified_sentence_en": "That original promise itself essentially established a constitutional document."
            }
        ]
    }
    return json.dumps(res_json_dict)

# --- JSON æå–ä¸æ ¡éªŒ ---
def extract_json_from_llm_response(raw_text):
    # å°è¯•æ¸…ç†å›´æ 
    json_text = re.sub(r'^\s*```(?:json)?\s*\n*', '', raw_text, flags=re.IGNORECASE | re.DOTALL)
    json_text = re.sub(r'\s*\n*```\s*$', '', json_text, flags=re.DOTALL)
    try:
        return json.loads(json_text)
    except (json.JSONDecodeError, TypeError):
        return None

def validate_analysis_json(data):
    required_keys = ["Source Sentence", "Translation", "StructureAnalysis", "Vocabulary", "Decomposition"]
    if not isinstance(data, dict):
        return False
    for key in required_keys:
        if key not in data:
            return False
    sa = data.get("StructureAnalysis", [])
    if not isinstance(sa, list):
        return False
    for item in sa:
        if not isinstance(item, dict):
            return False
        if item.get("highlight", False):
            if not item.get("segment") or not item.get("role") or not item.get("explanation_cn"):
                return False
    return True

# --- LLM è°ƒç”¨ï¼ˆå¸¦ç¼“å­˜ï¼‰ ---
def llm_english_analyze_with_time(englist_sentence, llm_type): 
    cache_key = hashlib.md5(englist_sentence.encode('utf-8')).hexdigest()
    current_time = time.time()
    llm_cache = st.session_state.llm_cache

    # ç¼“å­˜æ£€æŸ¥
    if cache_key in llm_cache:
        cached_entry = llm_cache[cache_key]
        if current_time - cached_entry['timestamp'] < CACHE_TTL_SECONDS:
            st.info("â„¹ï¸ **ç¼“å­˜å‘½ä¸­**: 30ç§’å†…é¿å…é‡å¤è°ƒç”¨ LLMã€‚")
            return cached_entry['result'], 0.0

    # è°ƒç”¨ LLM
    start_time = time.time()
    
    prompt_text = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‹±è¯­è¯­è¨€å­¦ä¸“å®¶å’Œé«˜çº§è¯­æ³•åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯å¯¹ç”¨æˆ·æä¾›çš„ä»»ä½•è‹±è¯­é•¿éš¾å¥è¿›è¡Œå½»åº•çš„ã€ç»“æ„åŒ–çš„è¯­æ³•è§£æå’Œè¯æ±‡è§£é‡Šã€‚

---
### **ä»»åŠ¡æŒ‡ä»¤**
è¯·å¯¹ç”¨æˆ·æä¾›çš„**å”¯ä¸€çš„è‹±æ–‡é•¿å¥**è¿›è¡Œåˆ†æï¼Œå¹¶**ä¸¥æ ¼**æŒ‰ç…§ä»¥ä¸‹å®šä¹‰çš„ **JSON ç»“æ„**è¿”å›ç»“æœã€‚

### **JSON ç»“æ„å’Œå†…å®¹è¦æ±‚**
ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯**çº¯ç²¹çš„ JSON æ ¼å¼**ï¼ˆä¸åŒ…å«ä»»ä½• Markdown æ ¼å¼å¦‚ ````json`ï¼Œä¹Ÿä¸åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—æˆ–å¼€åœºç™½ï¼‰ã€‚JSON å¯¹è±¡å¿…é¡»åŒ…å«ä»¥ä¸‹äº”ä¸ªé¡¶å±‚é”®ï¼ˆKeyï¼‰ï¼š

"Source Sentence"ï¼šå¯¹åº”å¤„ç†çš„åŸå§‹æ–‡æœ¬ã€‚
    * **Value ç±»å‹ï¼š** å­—ç¬¦ä¸² (string)
"Translation"ï¼šå¯¹åº”ä¸­æ–‡ç¿»è¯‘ã€‚
    * **Value ç±»å‹ï¼š** å­—ç¬¦ä¸² (string)
    * **å†…å®¹è¦æ±‚ï¼š** æä¾›ä¸€ä¸ªå‡†ç¡®ã€æµç•…çš„ä¸­æ–‡ç¿»è¯‘ã€‚

"StructureAnalysis"ï¼šå¯¹åº”å¥å­ç»“æ„åˆ†æã€‚
    * **Value ç±»å‹ï¼š** æ•°ç»„ (array)
    * **å†…å®¹è¦æ±‚ï¼š** æ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å››ä¸ªé”®ï¼š
        * `segment`: è‹±æ–‡éƒ¨åˆ† (English Segment)ã€‚**æ³¨æ„ï¼šæ‰€æœ‰ç‰‡æ®µå¿…é¡»æŒ‰é¡ºåºæ‹¼æ¥èµ·æ¥ï¼Œå®Œæ•´åœ°é‡æ„åŸè‹±æ–‡å¥ã€‚**
        * `highlight`: **å¸ƒå°”å€¼** (boolean)ã€‚å¦‚æœè¯¥ç‰‡æ®µæ˜¯éœ€è¦åˆ†æå’Œé«˜äº®çš„é‡è¦ç»“æ„ï¼ˆå¦‚ä¸»å¥ã€ä»å¥ï¼‰ï¼Œåˆ™ä¸º **true**ï¼›å¦åˆ™ï¼ˆå¦‚è¿æ¥è¯ã€ä¸é‡è¦çš„ä»‹è¯çŸ­è¯­ã€æ ‡ç‚¹ã€ç©ºæ ¼ï¼‰åˆ™ä¸º **false**ã€‚
        * `role`: ç»“æ„åç§°å’ŒåŠŸèƒ½ (Structure Name & Role)ã€‚**ä»…å½“ `highlight: true` æ—¶å¡«å……ã€‚** å¿…é¡»ç®€è¦æ¦‚æ‹¬å…¶ç»“æ„ç±»å‹å’Œè¯­æ³•åŠŸèƒ½ã€‚
        * `explanation_cn`: ä¸­æ–‡è§£é‡Š/å¤‡æ³¨ã€‚**ä»…å½“ `highlight: true` æ—¶å¡«å……ã€‚** è§£é‡Šè¯¥ç»“æ„çš„ä½œç”¨ã€‚
    * ã€éªŒè¯è¦æ±‚ã€‘å¿…é¡»ä¿è¯å…¨éƒ¨çš„segmentçš„ç»„åˆèµ·æ¥ä¸åŸå§‹å¥å­æ˜¯ä¸€è‡´çš„ã€‚

"Vocabulary"ï¼šå¯¹åº”æ ¸å¿ƒè¯æ±‡ã€‚
    * **Value ç±»å‹ï¼š** æ•°ç»„ (array)
    * **å†…å®¹è¦æ±‚ï¼š** æ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å››ä¸ªé”®ï¼š
        * `word`: è¯æ±‡ (Word)
        * `pos`: è¯æ€§ (Part of Speech)
        * `definition`: å®šä¹‰ (Definition)
        * `example`: ç¤ºä¾‹ (åŒ…å«è‹±æ–‡ä¾‹å¥åŠå…¶ä¸­æ–‡ç¿»è¯‘)

"Decomposition"ï¼šå¯¹åº”å¥å­æ‹†è§£ã€‚
    * **Value ç±»å‹ï¼š** æ•°ç»„ (array)
    * **å†…å®¹è¦æ±‚ï¼š** æ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹ä¸‰ä¸ªé”®ï¼š
        * `id`: åºå· (å¦‚ 1, 2, 3...)
        * `function`: åŠŸèƒ½ (Function)
        * `simplified_sentence_en`: æ‹†è§£åçš„ç®€å•**è‹±æ–‡**å¥

---
### **ä¸¥æ ¼çº¦æŸ**
1.  **è¾“å‡ºå¿…é¡»æ˜¯çº¯ç²¹ã€å®Œæ•´çš„ JSON å¯¹è±¡ï¼Œä¸å¯åŒ…å«ä»»ä½•å…¶ä»–æ–‡æœ¬ã€Markdown æ ¼å¼æˆ–è¯´æ˜ã€‚**
2.  å¿…é¡»ä¸¥æ ¼éµå¾ªä¸Šè¿°å®šä¹‰çš„ Key åç§°å’Œç»“æ„ã€‚

### **å¾…åˆ†æçš„è‹±æ–‡é•¿å¥**
{englist_sentence}
"""
    prompt = prompt_text.format(englist_sentence=englist_sentence)

    llm_result = None
    try:
        match llm_type:
            case "modelscope":
                extra_body = {"enable_thinking": False, "thinking_budget": 1024}
                response = modelscope_client.chat.completions.create(
                    model=model_name,
                    messages=[{'role': 'user', 'content': prompt}],
                    stream=False,
                    extra_body=extra_body
                )
                llm_result = response.choices[0].message.content
            case _:
                llm_result = get_mock_json_response(prompt)
    except Exception as e:
        st.error(f"LLM è°ƒç”¨å¤±è´¥: {e}")
        return None, 0.0

    end_time = time.time()
    elapsed_time = end_time - start_time
    
    json_result = extract_json_from_llm_response(llm_result)

    # æ›´æ–°ç¼“å­˜
    if json_result and validate_analysis_json(json_result):
        llm_cache_keys = list(llm_cache.keys())
        if len(llm_cache_keys) >= CACHE_SIZE_LIMIT:
            oldest_key = min(llm_cache_keys, key=lambda k: llm_cache[k]['timestamp'])
            del llm_cache[oldest_key]
        llm_cache[cache_key] = {
            'result': json_result,
            'timestamp': current_time
        }

    return json_result, elapsed_time

# --- âœ… ä¿®å¤æ ¸å¿ƒï¼šå®‰å…¨é«˜äº®å‡½æ•° ---
def create_instant_hover_highlight(segment: str, tooltip_content: str, color: str) -> str:
    """
    å®‰å…¨ç”Ÿæˆå¸¦ Tooltip çš„é«˜äº® HTMLï¼Œé˜²æ­¢ XSS å’Œæ¸²æŸ“å¤±è´¥ã€‚
    """
    # ğŸ”’ æ ¸å¿ƒï¼šä¸¥æ ¼è½¬ä¹‰ç”¨æˆ·å†…å®¹
    escaped_segment = html.escape(segment.strip())
    escaped_tooltip = html.escape(tooltip_content.strip(), quote=True)
    
    # ä½¿ç”¨ç´§å‡‘æ ¼å¼ï¼Œé¿å…å¤šä½™ç©ºæ ¼/æ¢è¡Œ
    return (
        f'<span class="custom-tooltip" '
        f'data-tooltip="{escaped_tooltip}" '
        f'style="'
        f'background-color: {color}; '
        f'border-bottom: 2px solid #ffbf00; '
        f'padding: 2px 0; '
        f'margin-right: 2px;'
        f'">'
        f'{escaped_segment}'
        f'</span>'
    )

# --- CSS æ ·å¼ ---
CUSTOM_CSS = """
<style>
/* é«˜äº®æ–‡æœ¬å®¹å™¨ï¼šä¿æŒ inlineï¼Œä½†ä¸º tooltip å®šä½æä¾›å‚è€ƒ */
.custom-tooltip {
    position: relative;
    display: inline-block;
    cursor: pointer;
    /* é¿å…è¡Œå†…å…ƒç´ é—´éš™é—®é¢˜ */
    vertical-align: bottom;
}

/* Tooltip ä¸»ä½“ */
.custom-tooltip::after {
    content: attr(data-tooltip);
    position: absolute;
    z-index: 2000; /* æé«˜é˜²æ­¢è¢«å…¶ä»–å…ƒç´ é®æŒ¡ */

    /* âœ… å›ºå®šå®½åº¦ + è‡ªé€‚åº”é«˜åº¦ */
    width: 350px;              /* â† å›ºå®šå®½åº¦ï¼šå¯è°ƒæ•´ä¸º 400px/500px */
    max-width: 90vw;           /* å“åº”å¼ï¼šä¸è¶…è¿‡è§†å£ 90% */
    white-space: normal;       /* å…è®¸æ¢è¡Œ */
    word-wrap: break-word;     /* å¼ºåˆ¶æ­¢é•¿è¯æ¢è¡Œ */
    text-align: left;

    /* æ ·å¼ç¾åŒ– */
    background-color: #2e2e2e;
    color: #ffffff;
    padding: 10px 14px;
    border-radius: 6px;
    font-size: 14px;
    line-height: 1.5;
    box-shadow: 0 4px 12px rgba(0,0,0,0.2);

    /* é»˜è®¤éšè— */
    opacity: 0;
    visibility: hidden;
    pointer-events: none;      /* é¼ æ ‡ç©¿é€ï¼Œé¿å…å¹²æ‰° hover */

    /* âœ… å®šä½ï¼šä»¥é«˜äº®æ–‡æœ¬ä¸­å¿ƒä¸ºåŸºå‡†ï¼Œå‘ä¸Šåç§» */
    top: auto;
    bottom: 100%;              /* ç´§è´´é«˜äº®æ–‡æœ¬ä¸Šæ–¹ */
    left: 50%;
    transform: translateX(-50%) translateY(8px); /* å‘ä¸Šåç§» 8px ç•™å‡ºé—´éš™ */

    /* åŠ¨ç”»ï¼šå³æ—¶æ˜¾ç¤ºï¼ˆ0sï¼‰ï¼Œä½†é€€å‡ºæ—¶å¯åŠ ä¸€ç‚¹å»¶è¿Ÿé¿å…é—ªè·³ */
    transition: opacity 0.15s ease, visibility 0.15s, transform 0.15s;
}

/* æ‚¬åœæ˜¾ç¤º */
.custom-tooltip:hover::after {
    opacity: 1;
    visibility: visible;
    transform: translateX(-50%) translateY(0); /* å‘ä¸Šç§»åŠ¨åˆ°æœ€ç»ˆä½ç½® */
}

/* âœ… å¯é€‰ï¼šæ·»åŠ å°ç®­å¤´ï¼ˆæŒ‡å‘é«˜äº®æ–‡æœ¬ï¼‰ */
.custom-tooltip::before {
    content: '';
    position: absolute;
    z-index: 2001;
    width: 0;
    height: 0;
    border-left: 6px solid transparent;
    border-right: 6px solid transparent;
    border-top: 6px solid #2e2e2e;
    top: auto;
    bottom: 100%;
    left: 50%;
    transform: translateX(-50%) translateY(2px); /* ç®­å¤´åœ¨ tooltip ä¸‹æ–¹ */
    opacity: 0;
    visibility: hidden;
    transition: opacity 0.15s, visibility 0.15s;
}
.custom-tooltip:hover::before {
    opacity: 1;
    visibility: visible;
}

/* æ·±è‰²æ¨¡å¼é€‚é…ï¼ˆStreamlit é»˜è®¤ï¼‰ */
[data-theme="dark"] .custom-tooltip::after {
    background-color: #3a3a3a;
}
[data-theme="dark"] .custom-tooltip::before {
    border-top-color: #3a3a3a;
}

/* æµ…è‰²æ¨¡å¼é€‚é…ï¼ˆå¦‚æœ‰ï¼‰*/
[data-theme="light"] .custom-tooltip::after {
    background-color: #333;
    color: #fff;
}
[data-theme="light"] .custom-tooltip::before {
    border-top-color: #333;
}
</style>
"""
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

# --- é¡µé¢é…ç½® ---
st.set_page_config(layout="wide", page_title="è‹±è¯­é•¿éš¾å¥åˆ†æå·¥å…·")
st.title("ğŸ“š è‹±è¯­é•¿éš¾å¥æ·±åº¦åˆ†æå™¨")
st.subheader(f"åŸºäºç»“æ„åŒ– JSON è¾“å‡ºçš„è§£æå’Œå¯è§†åŒ– | LLM: **{model_type}** ***{model_name}***")

default_sentence = "Although the manifesto pledged that henceforth no law would go into effect without the approval of a popularly elected legislature, the Court seemed unaware that this pledge entailed a constitutional charter."
sentence_input = st.text_area("è¾“å…¥è‹±æ–‡é•¿éš¾å¥:", default_sentence, height=100)

if st.button("å¼€å§‹åˆ†æ", type="primary"):
    if not sentence_input.strip():
        st.error("è¯·è¾“å…¥ä¸€ä¸ªè‹±æ–‡å¥å­è¿›è¡Œåˆ†æã€‚")
        st.stop()

    with st.spinner("æ­£åœ¨è°ƒç”¨ LLM æˆ–æ£€æŸ¥ç¼“å­˜..."):
        analysis_json, elapsed_time = llm_english_analyze_with_time(sentence_input.strip(), llm_type=model_type) 
    
    if analysis_json is None or not validate_analysis_json(analysis_json):
        st.error("âŒ åˆ†æå¤±è´¥ï¼šLLM è¿”å›ç»“æœä¸ºç©ºæˆ– JSON æ ¼å¼éæ³•ã€‚")
        if analysis_json:
            st.json(analysis_json)
        st.stop()
    
    if elapsed_time > 0.0:
        st.info(f"â±ï¸ **LLM åˆ†æè€—æ—¶**: **{elapsed_time:.2f}** ç§’")
    
    source_sentence_llm = analysis_json.get("Source Sentence", "").strip()
    if source_sentence_llm and source_sentence_llm != sentence_input.strip():
        st.warning(f"âš ï¸ LLM å¤„ç†çš„å¥å­ä¸è¾“å…¥ç•¥æœ‰ä¸åŒï¼š\n`{source_sentence_llm}`")

    st.success("âœ… åˆ†æå®Œæˆï¼")
    st.divider()

    # --- 1. ç¿»è¯‘ ---
    st.header("1. ğŸ”§ ä¸­æ–‡ç¿»è¯‘ (Translation)")
    st.info(analysis_json.get("Translation", "N/A"))
    st.divider()

    # --- 2. ç»“æ„é«˜äº®ï¼ˆâœ… ä¿®å¤é‡ç‚¹ï¼‰---
    st.header("2. ğŸ§ å¥å­ç»“æ„åˆ†æ (Interactive Highlight)")
    st.caption("æ‚¬åœé«˜äº®éƒ¨åˆ†æŸ¥çœ‹è¯­æ³•è§’è‰²ä¸è§£é‡Š")

    structure_data = analysis_json.get("StructureAnalysis", [])
    HIGHLIGHT_COLORS = ["#fce8a9", "#a9fce8", "#e8a9fc", "#fcd9a9"]
    color_index = 0
    highlighted_parts = []

    for item in structure_data:
        segment = item.get("segment", "")
        is_highlight = item.get("highlight", False)
        
        if is_highlight and segment.strip():
            color = HIGHLIGHT_COLORS[color_index % len(HIGHLIGHT_COLORS)]
            color_index += 1
            role = item.get("role", "ç»“æ„")
            explanation = item.get("explanation_cn", "æ— è§£é‡Š")
            tooltip = f"ã€{role}ã€‘: {explanation}"
            highlighted_parts.append(create_instant_hover_highlight(segment, tooltip, color))
        else:
            # éé«˜äº®éƒ¨åˆ†ä¹Ÿ escapeï¼Œé˜²å°–æ‹¬å·ç ´å
            escaped_plain = html.escape(segment)
            highlighted_parts.append(escaped_plain)
    
    # æ‹¼æ¥ä¸ºç´§å‡‘ HTML å­—ç¬¦ä¸²
    highlighted_sentence = "".join(highlighted_parts).strip()

    st.markdown("**åŸå¥:**")
    # âœ… å…³é”®ï¼šä½¿ç”¨ st.html() æ¸²æŸ“ï¼ˆStreamlit â‰¥1.34ï¼‰
    try:
        st.html(highlighted_sentence)
    except AttributeError:
        # å…¼å®¹æ—§ç‰ˆ Streamlitï¼ˆä¸æ¨èé•¿æœŸä½¿ç”¨ï¼‰
        st.warning("è¯·å‡çº§ Streamlit åˆ° â‰¥1.34 ä»¥è·å¾—æœ€ä½³ HTML æ¸²æŸ“æ•ˆæœï¼")
        st.markdown(highlighted_sentence, unsafe_allow_html=True)

    # --- 2b. é«˜äº®ç‰‡æ®µå¡ç‰‡å±•ç¤º ---
    st.header("2b. ğŸ´ é«˜äº®ç‰‡æ®µå¡ç‰‡å±•ç¤º")
    st.caption("æ¯å¼ å¡ç‰‡æ˜¾ç¤ºåŸå¥ä¸­çš„ä¸€ä¸ªé«˜äº®éƒ¨åˆ†åŠå…¶è¯­æ³•è§’è‰²ä¸è§£é‡Š")

    for idx, item in enumerate(structure_data):
        segment = item.get("segment", "").strip()
        is_highlight = item.get("highlight", False)
        
        if is_highlight and segment:
            color = HIGHLIGHT_COLORS[idx % len(HIGHLIGHT_COLORS)]
            role = item.get("role", "ç»“æ„")
            explanation = item.get("explanation_cn", "æ— è§£é‡Š")
            
            card_html = f"""
            <div style="
                background-color: {color};
                padding: 12px 16px;
                margin-bottom: 8px;
                border-radius: 12px;
                box-shadow: 0 2px 6px rgba(0,0,0,0.15);
            ">
                <strong>åŸå¥ç‰‡æ®µ:</strong> {html.escape(segment)}<br>
                <strong>è§’è‰²:</strong> {role}<br>
                <strong>è§£é‡Š:</strong> {explanation}
            </div>
            """
            try:
                st.html(card_html)
            except AttributeError:
                st.markdown(card_html, unsafe_allow_html=True)

    st.divider()

    # --- 3. è¯æ±‡ ---
    st.header("3. ğŸ”‘ æ ¸å¿ƒè¯æ±‡ (Key Vocabulary)")
    vocab_data = analysis_json.get("Vocabulary", [])
    if vocab_data:
        df_vocab = pd.DataFrame(vocab_data)
        df_vocab.columns = ["è¯æ±‡ (Word)", "è¯æ€§ (POS)", "å®šä¹‰ (Definition)", "ç¤ºä¾‹ (Example)"]
        st.table(df_vocab)
    st.divider()

    # --- 4. æ‹†è§£ ---
    st.header("4. âœ¨ å¥å­æ‹†è§£ (Sentence Decomposition)")
    decomp_data = analysis_json.get("Decomposition", [])
    if decomp_data:
        df_decomp = pd.DataFrame(decomp_data)
        df_decomp.columns = ["ID", "åŠŸèƒ½ (Function)", "æ‹†è§£åçš„ç®€å•è‹±æ–‡å¥ (Simplified English Sentence)"]
        st.table(df_decomp)